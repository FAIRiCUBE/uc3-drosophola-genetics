{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06566ba3-988d-46c6-80e9-3fb38acef589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import xarray as xr\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877e6105-cce5-448b-bcfb-85d1687a453f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91dd25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sonjastndl/s3/ClimateData\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d807ddc-afef-450f-b64d-3e01bfb31521",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c.retrieve(\n",
    "    'derived-near-surface-meteorological-variables',\n",
    "    {\n",
    "        'version': '2.1',\n",
    "        'format': 'tgz',\n",
    "        'variable': 'near_surface_air_temperature',\n",
    "        'year': [\n",
    "            '2012', '2013', '2014',\n",
    "            '2015', '2016', '2017',\n",
    "            '2018', '2019',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'reference_dataset': 'cru',\n",
    "    },\n",
    "    '/home/sonjastndl/s3/ClimateData/climatedata/download.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edb527-58e7-43c0-944e-f0c1852cb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf /home/sonjastndl/s3/ClimateData/climatedata/download.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb95949e-aba3-476d-8e01-af420f75db78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 70128, lon: 720, lat: 360)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2012-01-01 ... 2019-12-31T23:00:00\n",
      "  * lon      (lon) float64 -179.8 -179.2 -178.8 -178.2 ... 178.8 179.2 179.8\n",
      "  * lat      (lat) float64 -89.75 -89.25 -88.75 -88.25 ... 88.75 89.25 89.75\n",
      "Data variables:\n",
      "    Tair     (time, lat, lon) float32 dask.array<chunksize=(744, 360, 720), meta=np.ndarray>\n",
      "Attributes:\n",
      "    title:        WATCH Forcing Data methodology applied to ERA5 data\n",
      "    institution:  Copernicus Climate Change Service\n",
      "    contact:      http://copernicus-support.ecmwf.int\n",
      "    comment:      Methodology implementation for ERA5 and dataset production ...\n",
      "    Conventions:  CF-1.7\n",
      "    summary:      ERA5 data regridded to half degree regular lat-lon; Genuine...\n",
      "    reference:    Cucchi et al., 2020, Earth Syst. Sci. Data, 12(3), 2097â€“212...\n",
      "    licence:      The dataset is distributed under the Licence to Use Coperni...\n"
     ]
    }
   ],
   "source": [
    "file_pattern = \"/home/sonjastndl/s3/ClimateData/climatedata/Tair_WFDE5_CRU_*.nc\"\n",
    "files = glob.glob(file_pattern)\n",
    "# Open multiple datasets and concatenate them along the time dimension\n",
    "ds = xr.open_mfdataset(files, combine='by_coords')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec63652-9623-4b60-ae48-e9b8d40dd5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_csv_file=\"/home/sonjastndl/s3/ClimateData/TESTMARIA_5.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01ce503-679e-451e-be89-516a5a046520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/home/sonjastndl/s3/LGA/uc3-drosophola-genetics/projects/LandscapeGenomicsPipeline/EOXHUB_TEST3/dest_v2.samps_3May2024.csv\", newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        try:\n",
    "            day=int(row[10])\n",
    "        except ValueError:\n",
    "            continue\n",
    "        month=int(row[12])\n",
    "        year=row[13]\n",
    "        sampleId=row[0]\n",
    "        lat=row[3]\n",
    "        lon=row[4]\n",
    "        day2=\"{0:0=2d}\".format(day)\n",
    "        month2=\"{0:0=2d}\".format(month)\n",
    "        date=year+\"-\"+month2+\"-\"+day2\n",
    "        #print(date)\n",
    "        with open (output_csv_file, \"a\") as o:\n",
    "            spamwriter = csv.writer(o, delimiter=',')\n",
    "            TG_location = ds.Tair.sel(lon=lon,lat=lat, method='nearest')\n",
    "            try:\n",
    "                Subset_time_and_loation= TG_location.sel(time=str(date))\n",
    "                WW=Subset_time_and_loation.to_dataframe()\n",
    "                mtemp= WW.Tair.mean()\n",
    "                #print(date)\n",
    "                #print(mtemp)\n",
    "                o.write(sampleId + \",\" + str(mtemp)+\"\\n\")\n",
    "            except KeyError:\n",
    "                o.write(sampleId + \",\" + \"NA\" +\"\\n\")\n",
    "            #o.write(\"test\" +sampleId + str(mtemp)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b73b6d9-bdf1-4ff8-840a-2f55db35d8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/home/sonjastndl/s3/LGA/uc3-drosophola-genetics/projects/LandscapeGenomicsPipeline/EOXHUB_TEST3/dest_v2.samps_3May2024.csv\", newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    with open(output_csv_file, \"a\") as o:\n",
    "        spamwriter = csv.writer(o, delimiter=',')\n",
    "        o.write(\"sampleId,NSAT\" +\"\\n\")\n",
    "        # Iterate over rows in the input CSV file\n",
    "        for row in spamreader:\n",
    "            try:\n",
    "                day = int(row[10])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            month = int(row[12])\n",
    "            year = row[13]\n",
    "            sampleId = row[0]\n",
    "            lat = row[3]\n",
    "            lon = row[4]\n",
    "            day2 = \"{0:0=2d}\".format(day)\n",
    "            month2 = \"{0:0=2d}\".format(month)\n",
    "            date = year + \"-\" + month2 + \"-\" + day2 \n",
    "            # Write header once if not already written\n",
    "            TG_location = ds.Tair.sel(lon=lon, lat=lat, method='nearest')\n",
    "            try:\n",
    "                Subset_time_and_loation= TG_location.sel(time=str(date))\n",
    "                WW=Subset_time_and_loation.to_dataframe()\n",
    "                mtemp= WW.Tair.mean()\n",
    "                #print(date)\n",
    "                #print(mtemp)\n",
    "                o.write(sampleId + \",\" + str(mtemp)+\"\\n\")\n",
    "            except KeyError:\n",
    "                o.write(sampleId + \",\" + \"NA\" +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d52926-ee8f-4f98-ae7c-2a8bf99c3fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##if you want e.g. have NSAT 50 days before sampling\n",
    "#get average of weeks before sampling\n",
    "#import datetime\n",
    "#u = datetime.datetime.strptime(date,\"%Y-%m-%d\")\n",
    "#d = datetime.timedelta(days=50)\n",
    "#t = u - d\n",
    "#print(t)\n",
    "\n",
    "##spanwidth of temperatures for that day/week/moth whatever\n",
    "#abs(WW.Tair.min()-WW.Tair.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairicube-edc-2022.10-14",
   "language": "python",
   "name": "conda-env-fairicube-edc-2022.10-14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
